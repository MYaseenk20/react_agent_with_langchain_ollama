# ðŸ§  ReAct Agent with LangChain & Ollama

This project demonstrates a **manual implementation of the ReAct (Reason + Act) agent pattern** using **LangChain**, **Ollama**, and a **custom tool execution loop**.

Instead of relying on `AgentExecutor`, this example shows **how ReAct works internally**, giving you full control and understanding of the agentâ€™s reasoning and tool usage.

---

## ðŸš€ Features

- âœ… Custom **ReAct prompt**  
  *(Thought â†’ Action â†’ Observation â†’ Final Answer)*
- âœ… Tool calling **without `AgentExecutor`**
- âœ… Manual agent loop using `AgentAction` and `AgentFinish`
- âœ… Uses **Ollama local models** (`gemma2`)
- âœ… Callback support for debugging agent behavior
- âœ… Simple example tool: `get_text_length`

---

## ðŸ§  How the ReAct Agent Works

1. **LLM receives the question**
2. **LLM reasons** (`Thought`)
3. **LLM selects a tool** (`Action`)
4. **Tool is executed**
5. **Observation is added to the scratchpad**
6. **LLM continues reasoning**
7. **Final answer is produced**

This loop continues until the LLM returns **`Final Answer`**.

---

## ðŸ¤– Tech Stack

- **Python**
- **LangChain**
- **Ollama**
- **ReAct prompting pattern**


- Debug tool-calling behavior
- Experiment with local LLMs using Ollama
